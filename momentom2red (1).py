# -*- coding: utf-8 -*-
"""MomentoM2Red

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mpLPl6DzN2grJZgxqdcaUSUO8SiU4sZY
"""

# Importación de las librerías
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier

# Importar el dataset y limpiarlo
df = pd.read_csv("Calorias FastF.csv")
df = df.apply(pd.to_numeric, errors='coerce')
df['Calories'] = np.where(df['Calories'] > 219, 'Si', "No")
df = df.dropna()

# Definir X y Y (Combinación de x e y originales)
X = df[['Calories from\nFat', 'Saturated Fat\n(g)']].values  # Combinación de x e y
Y = df['Calories'].values  # 'Calories' será la variable dependiente

# Dividir el dataset en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Dividir el conjunto de entrenamiento en entrenamiento y validación (80% entrenamiento, 20% validación)
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

# Inicialización y entrenamiento del modelo de red neuronal
# Usamos MLPClassifier con una sola capa oculta de 10 neuronas
modelo = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)
modelo.fit(x_train, y_train)

# RESULTADOS DE ENTRENAMIENTO

# Predicciones en el conjunto de entrenamiento
predicciones_train = modelo.predict(x_train)
# Generar la matriz de confusión para los datos de entrenamiento
cm_train = confusion_matrix(y_train, predicciones_train)
disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=modelo.classes_)

# Mostrar visualmente la matriz de confusión para los datos de entrenamiento
disp_train.plot(cmap=plt.cm.Reds)
plt.title("Entrenamiento")
plt.show()

# Calcular las métricas de evaluación en el conjunto de entrenamiento
precision = precision_score(y_train, predicciones_train, average='weighted')
recall = recall_score(y_train, predicciones_train, average='weighted')
f1 = f1_score(y_train, predicciones_train, average='weighted')

# Mostrar las métricas de evaluación
print(f"Precisión en entrenamiento: {precision:.2f}")
print(f"Recall en entrenamiento: {recall:.2f}")
print(f"F1 Score en entrenamiento: {f1:.2f} \n")

# RESULTADOS DE VALIDACIÓN

# Predicciones en el conjunto de validación
predicciones_val = modelo.predict(x_val)
# Generar la matriz de confusión para los datos de validación
cm_val = confusion_matrix(y_val, predicciones_val)
disp_val = ConfusionMatrixDisplay(confusion_matrix=cm_val, display_labels=modelo.classes_)

# Mostrar visualmente la matriz de confusión para los datos de validación
disp_val.plot(cmap=plt.cm.Reds)
plt.title("Validación")
plt.show()

# Calcular las métricas de evaluación en el conjunto de validación
precision = precision_score(y_val, predicciones_val, average='weighted')
recall = recall_score(y_val, predicciones_val, average='weighted')
f1 = f1_score(y_val, predicciones_val, average='weighted')

# Mostrar las métricas de evaluación
print(f"Precisión en validación: {precision:.2f}")
print(f"Recall en validación: {recall:.2f}")
print(f"F1 Score en validación: {f1:.2f} \n")

# RESULTADOS DE PRUEBA

# Predicciones en el conjunto de prueba
predicciones_test = modelo.predict(x_test)
# Generar la matriz de confusión para los datos de prueba
cm_test = confusion_matrix(y_test, predicciones_test)
disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=modelo.classes_)

# Mostrar visualmente la matriz de confusión para los datos de prueba
disp_test.plot(cmap=plt.cm.Reds)
plt.title("Prueba")
plt.show()

# Calcular las métricas de evaluación en el conjunto de prueba
precision = precision_score(y_test, predicciones_test, average='weighted')
recall = recall_score(y_test, predicciones_test, average='weighted')
f1 = f1_score(y_test, predicciones_test, average='weighted')

# Mostrar las métricas de evaluación
print(f"Precisión en prueba: {precision:.2f}")
print(f"Recall en prueba: {recall:.2f}")
print(f"F1 Score en prueba: {f1:.2f} \n")